@article{zou2023universal,
  title   = {Universal and Transferable Adversarial Attacks on Aligned Language Models},
  author  = {Andy Zou and Zifan Wang and Nicholas Carlini and Milad Nasr and J. Zico Kolter and Matt Fredrikson},
  journal = {arXiv},
  year    = {2023},
  eprint  = {2307.15043},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CL},
  doi     = {10.48550/arXiv.2307.15043},
  url     = {https://arxiv.org/abs/2307.15043}
}


@inproceedings{Chen2025StruQ,
  title     = {StruQ: Defending Against Prompt Injection with Structured Queries},
  author    = {Sizhe Chen and Julien Piet and Chawin Sitawarin and David Wagner},
  booktitle = {Proceedings of the 34th USENIX Security Symposium (USENIX Security '25)},
  year      = {2025},
  month     = aug,
  address   = {Seattle, WA, USA},
  publisher = {USENIX Association},
  note      = {To appear; prepublication PDF available},
  url       = {https://www.usenix.org/system/files/usenixsecurity25-sec24winter-prepub-468-chen-sizhe.pdf}
}

@inproceedings{sundararajan2017,
  author    = {Mukund Sundararajan and Ankur Taly and Qiqi Yan},
  title     = {Axiomatic Attribution for Deep Networks},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning (ICML 2017)},
  year      = {2017},
  pages     = {3319--3328},
  publisher = {JMLR},
  series    = {Proceedings of Machine Learning Research},
  location  = {Sydney, Australia},
  url       = {https://proceedings.mlr.press/v70/sundararajan17a.html}
}

@article{ivry2025sentinel,
  title   = {Sentinel: SOTA Model to Protect Against Prompt Injections},
  author  = {Dror Ivry and Oran Nahum},
  year    = {2025},
  journal = {arXiv},
  eprint  = {2506.05446},
  archivePrefix = {arXiv},
  primaryClass  = {cs.AI},
  url     = {https://arxiv.org/abs/2506.05446}
}

@online{cefalu2022,
  title   = {Declassifying the Responsible Disclosure of the Prompt Injection Attack Vulnerability of GPT-3},
  author  = {Jonathan Cefalu},
  year    = {2022},
  url     = {https://www.preamble.com/prompt-injection-a-critical-vulnerability-in-the-gpt-3-transformer-and-how-we-can-begin-to-solve-it}
}

@online{goodside2022,
  author  = {Riley Goodside},
  title   = {Exploiting GPT-3 prompts with malicious inputs that order the model to ignore its previous directions},
  year    = {2022},
  month   = sep,
  url     = {https://twitter.com/goodside/status/1569388491612547073},
  note    = {Tweet}
}

@online{willison2022,
  author  = {Simon Willison},
  title   = {Prompt Injection Attacks against GPT-3},
  year    = {2022},
  month   = sep,
  url     = {https://simonwillison.net/2022/Sep/12/prompt-injection/}
}

@online{llmguardv2,
  author = {Protect AI},
  title  = {LLM Guard v2: Fine-Tuned DeBERTa-v3 for Prompt Injection Detection},
  year   = {2024},
  url    = {https://huggingface.co/protectai/deberta-v3-base-prompt-injection-v2},
  note   = {Model card}
}

@inproceedings{ayub2024embedding,
  author    = {Md. Ahsan Ayub and Subhabrata Majumdar},
  title     = {Embedding-based Classifiers Can Detect Prompt Injection Attacks},
  booktitle = {Proceedings of the 2024 Conference on Applied Machine Learning for Information Security (CAMLIS)},
  year      = {2024},
  publisher = {CEUR Workshop Proceedings},
  url       = {https://ceur-ws.org/Vol-3920/paper15.pdf}
}

@inproceedings{hung2025attention,
  author    = {Kuo-Han Hung and Ching-Yun Ko and Ambrish Rawat and I-Hsin Chung and Winston Hsu and Pin-Yu Chen},
  title     = {Attention Tracker: Detecting Prompt Injection Attacks in LLMs},
  booktitle = {Findings of the Association for Computational Linguistics: NAACL 2025},
  pages     = {2309--2322},
  year      = {2025},
  month     = apr,
  address   = {Mexico City, Mexico},
  publisher = {Association for Computational Linguistics},
  doi       = {10.18653/v1/2025.findings-naacl.123},
  url       = {https://aclanthology.org/2025.findings-naacl.123/}
}

@inproceedings{secalign2025,
  author    = {Sizhe Chen and Arman Zharmagambetov and Saeed Mahloujifar and Kamalika Chaudhuri and David Wagner and Chuan Guo},
  title     = {SecAlign: Defending Against Prompt Injection with Preference Optimization},
  booktitle = {Proceedings of the 2025 ACM SIGSAC Conference on Computer and Communications Security (CCS '25)},
  year      = {2025},
  month     = oct,
  address   = {Taipei, Taiwan},
  publisher = {ACM},
  note      = {To appear},
  url       = {https://arxiv.org/abs/2410.05451},
  eprint    = {2410.05451},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CR}
}

@article{wallace2024instructionhierarchy,
  title   = {The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions},
  author  = {Eric Wallace and Kai Xiao and Reimar Leike and Lilian Weng and Johannes Heidecke and Alex Beutel},
  journal = {arXiv},
  year    = {2024},
  eprint  = {2404.13208},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CR},
  doi     = {10.48550/arXiv.2404.13208},
  url     = {https://arxiv.org/abs/2404.13208}
}

@article{ise2025,
  author  = {Tong Wu and Shujian Zhang and Kaiqiang Song and Silei Xu and Sanqiang Zhao and Ravi Agrawal and Sathish Reddy Indurthi and Chong Xiang and Prateek Mittal and Wenxuan Zhou},
  title   = {Instructional Segment Embedding: Improving LLM Safety with Instruction Hierarchy},
  journal = {arXiv},
  year    = {2025},
  eprint  = {2410.09102},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CL},
  url     = {https://arxiv.org/abs/2410.09102}
}

@inproceedings{xie2024gradsafe,
  title     = {GradSafe: Detecting Jailbreak Prompts for LLMs via Safety-Critical Gradient Analysis},
  author    = {Yueqi Xie and Minghong Fang and Renjie Pi and Neil Zhenqiang Gong},
  booktitle = {Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages     = {507--518},
  year      = {2024},
  month     = aug,
  address   = {Bangkok, Thailand},
  publisher = {Association for Computational Linguistics},
  doi       = {10.18653/v1/2024.acl-long.30},
  url       = {https://aclanthology.org/2024.acl-long.30/}
}

@inproceedings{chen2025indirect,
  title     = {Can Indirect Prompt Injection Attacks Be Detected and Removed?},
  author    = {Yulin Chen and Haoran Li and Yuan Sui and Yufei He and Yue Liu and Yangqiu Song and Bryan Hooi},
  booktitle = {Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages     = {18189--18206},
  year      = {2025},
  month     = jul,
  address   = {Vienna, Austria},
  publisher = {Association for Computational Linguistics},
  isbn      = {979-8-89176-251-0},
  url       = {https://aclanthology.org/2025.acl-long.890/}
}

@article{mchugh2025pi2,
  author  = {Jeremy McHugh and Kristina {\v{S}}ekrst and Jon Cefalu},
  title   = {Prompt Injection 2.0: Hybrid AI Threats},
  journal = {arXiv},
  year    = {2025},
  eprint  = {2507.13169},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CR},
  url     = {https://arxiv.org/abs/2507.13169}
}

@online{willison2023dualllm,
  author = {Simon Willison},
  title  = {The Dual LLM Pattern for Building AI Assistants That Can Resist Prompt Injection},
  year   = {2023},
  url    = {https://simonwillison.net/2023/Apr/25/dual-llm-pattern/},
  note   = {Blog post, 25 April 2023}
}

@article{camel2025,
  author  = {Edoardo Debenedetti and Ilia Shumailov and Tianqi Fan and Jamie Hayes and Nicholas Carlini and Daniel Fabian and Christoph Kern and Chongyang Shi and Andreas Terzis and Florian Tram{\`e}r},
  title   = {Defeating Prompt Injections by Design},
  journal = {arXiv},
  year    = {2025},
  eprint  = {2503.18813},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CR},
  url     = {https://arxiv.org/abs/2503.18813}
}

@online{willison2025camel,
  author = {Simon Willison},
  title  = {CaMeL offers a promising new direction for mitigating prompt injection attacks},
  year   = {2025},
  url    = {https://simonwillison.net/2025/Apr/11/camel/},
  note   = {Blog post}
}

@article{meta2024llama3,
  title   = {The Llama 3 Herd of Models},
  author  = {Meta AI},
  year    = {2024},
  journal = {arXiv},
  eprint  = {2407.21783},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CL},
  url     = {https://arxiv.org/abs/2407.21783}
}

@online{meta2024llama31blog,
  title  = {Introducing Llama 3.1: Our most capable models to date},
  author = {Meta AI},
  year   = {2024},
  url    = {https://ai.meta.com/blog/meta-llama-3-1/},
  note   = {July 23, 2024}
}

@online{meta2024llama31card,
  title  = {Llama 3.1 Model Cards and Prompt Formats},
  author = {Meta AI},
  year   = {2024},
  url    = {https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_1/}
}

@online{meta2024llama32,
  title  = {Llama 3.2: Revolutionizing edge AI and vision with open, customizable models},
  author = {Meta AI},
  year   = {2024},
  url    = {https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/},
  note   = {September 25, 2024}
}

@online{meta2024llama32card,
  title  = {Llama 3.2 Model Cards and Prompt Formats},
  author = {Meta AI},
  year   = {2024},
  url    = {https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_2/}
}

@article{qwen2024v25,
  title   = {Qwen2.5 Technical Report},
  author  = {An Yang and others},
  year    = {2024},
  journal = {arXiv},
  eprint  = {2412.15115},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CL},
  url     = {https://arxiv.org/abs/2412.15115}
}

@article{qwen2025v3,
  title   = {Qwen3 Technical Report},
  author  = {An Yang and others},
  year    = {2025},
  journal = {arXiv},
  eprint  = {2505.09388},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CL},
  url     = {https://arxiv.org/abs/2505.09388}
}

@inproceedings{hu2024gradientcuff-neurips,
  author    = {Xiaomeng Hu and Pin-Yu Chen and Tsung-Yi Ho},
  title     = {Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landscapes},
  booktitle = {NeurIPS 2024},
  year      = {2024},
  note      = {Poster},
  url       = {https://neurips.cc/virtual/2024/poster/93211}
}

@article{hu2025attentionslipping,
  title   = {Attention Slipping: A Mechanistic Understanding of Jailbreak Attacks and Defenses in LLMs},
  author  = {Xiaomeng Hu and Pin-Yu Chen and Tsung-Yi Ho},
  journal = {arXiv},
  year    = {2025},
  eprint  = {2507.04365},
  archivePrefix = {arXiv},
  primaryClass  = {cs.CR},
  doi     = {10.48550/arXiv.2507.04365},
  url     = {https://arxiv.org/abs/2507.04365}
}

@inproceedings{hu2025tokenhighlighter,
  author    = {Xiaomeng Hu and Pin-Yu Chen and Tsung-Yi Ho},
  title     = {Token Highlighter: Inspecting and Mitigating Jailbreak Prompts for Large Language Models},
  booktitle = {Proceedings of the 39th AAAI Conference on Artificial Intelligence (AAAI-25)},
  year      = {2025},
  pages     = {27330--27338},
  publisher = {AAAI Press},
  doi       = {10.1609/aaai.v39i26.34943},
  url       = {https://ojs.aaai.org/index.php/AAAI/article/view/34943}
}

@article{efron1987bca,
  title   = {Better Bootstrap Confidence Intervals},
  author  = {Bradley Efron},
  journal = {Journal of the American Statistical Association},
  year    = {1987},
  volume  = {82},
  number  = {397},
  pages   = {171--185},
  doi     = {10.1080/01621459.1987.10478410}
}

@online{openai2025prompting,
  author = {OpenAI},
  title  = {Prompting — OpenAI API},
  year   = {2025},
  url    = {https://platform.openai.com/docs/guides/prompting},
  note   = {Guidance on what to put in system vs. user messages}
}

@inproceedings{liu2025datasentinel,
  author    = {Yupei Liu and Yuqi Jia and Jinyuan Jia and Dawn Song and Neil Zhenqiang Gong},
  title     = {DataSentinel: A Game-Theoretic Detection of Prompt Injection Attacks},
  booktitle = {2025 IEEE Symposium on Security and Privacy (SP)},
  pages     = {2190--2208},
  year      = {2025},
  month     = may,
  address   = {San Francisco, CA, USA},
  publisher = {IEEE},
  doi       = {10.1109/SP61157.2025.00250},
  url       = {https://doi.org/10.1109/SP61157.2025.00250}
}

